# Requirements for ai_local app
llama-cpp-python>=0.2.0

# For GPU support (optional - uncomment if you have CUDA):
# llama-cpp-python[cuda]>=0.2.0

# For Metal support on macOS (optional - uncomment if on macOS with Metal):
# llama-cpp-python[metal]>=0.2.0
